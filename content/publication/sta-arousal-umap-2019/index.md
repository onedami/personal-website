+++
title = "Combining Trending Scan Paths with Arousal to Model Visual Behaviour on the Web: A Case Study of Neurotypical People vs People with Autism"
date = 2019-06-06T00:00:00
draft = false

# Authors. Comma separated list, e.g. `["Bob Smith", "David Jones"]`.
authors = ["Oludamilare Matthews", "Sukru Eraslan","Victoria Yaneva","Alan Davies","Yeliz Yesilada","Markel Vigo", "Simon Harper"]

# Publication type.
# Legend:
# 0 = Uncategorized
# 1 = Conference paper
# 2 = Journal article
# 3 = Manuscript
# 4 = Report
# 5 = Book
# 6 = Book section
publication_types = ["1"]

# Publication name and optional abbreviated version.
publication = "12th International Conference on Methods and Techniques in Behavioral Research (2018)"
publication_short = "Measuring Behaviour 2018"

# Abstract and optional shortened version.
abstract = "People with autism often exhibit different visual behaviours from neurotypical users. To explore how these differences are exhibited on the Web, we model visual behaviour by combining pupillary response, which is an unobtrusive measure of physiological arousal, with eye-tracking scan paths that indicate visual attention. We evaluated our approach with two populations: 19 neurotypical users and 19 users with autism. We observe differences in their visual behaviours as, in certain instances, individuals with autism exhibit a lower arousal response to affective contents. While this is consistent with the literature on autism, we confirm this phenomenon on the Web. We discuss how our modelling method can be used to identify possible UX issues such as the presence of stress, cognitive load and differences in the perception of Web elements in relation to physiological arousal."
abstract_short = "We have demonstrated through our study that it is possible to combine methods that answer both of these questions, ‘how do users interact with websites’ and ‘how do they feel when they interact with web pages. The former was achieved by summarising the users’ visual scan paths into a trending scan path using the STA algorithm, while the later was achieved by generating arousal scores that each UI element elicits for each group of users through our arousal sensing algorithm. Furthermore, we created a novel visualisation that can aid researchers in assimilating and generating research questions that can be investigated further using more established statistical or qualitative methods."

# Is this a selected publication? (true/false)
selected = true

# Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["deep-learning"]` references 
#   `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects = ["sensing-arousal"]

# Tags (optional).
#   Set `tags = []` for no tags, or use the form `tags = ["A Tag", "Another Tag"]` for one or more tags.
tags = []

# Links (optional).
url_pdf = "https://www.researchgate.net/publication/333731306_Combining_Trending_Scan_Paths_with_Arousal_to_Model_Visual_Behaviour_on_the_Web_A_Case_Study_of_Neurotypical_People_vs_People_with_Autism"
url_preprint = ""
url_code = ""
url_dataset = ""
url_project = ""
url_slides = ""
url_video = ""
url_poster = ""
url_source = ""

# Custom links (optional).
#   Uncomment line below to enable. For multiple links, use the form `[{...}, {...}, {...}]`.
# url_custom = [{name = "Custom Link", url = "http://example.org"}]

# Digital Object Identifier (DOI)
doi = "10.1145/3320435.3320446"

# Does this page contain LaTeX math? (true/false)
math = true

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder. 
[image]
  # Caption (optional)
  caption = ""

  # Focal point (optional)
  # Options: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight
  focal_point = ""
+++
