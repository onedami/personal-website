+++
# Project title.
title = "Sensing-arousal"

# Date this page was created.
date = 2016-04-27T00:00:00

# Project summary to display on homepage.
summary = "Arousal is often used as a proxy to measure stress, frustration, anxiety, boredom and attention which are of particular interest to researchers of behavioral science and HCI. Our goal is to develop a method to sense arousal during user interaction with interactive contents. Our method analyzes pupillary response from eye trackers but has the potential to be deployed in future web cameras which is useful in non-laboratory settings." 
# Our approach has undergone evaluations using cognitive stimulus (using Stroop's effect), emotional stimulus (using images from IAPS). Most importantly, it has been evaluated on real life web browsing tasks while participants experienced flikering of the mouse pointer in pointing tasks, pop-ups in reading tasks, session time-outs in a booking task, and system failure in an information retrieval task. Our algorithm was able to discriminate between moments of frustration during these events (simulated using userscripts - violent monkey), whilst also identifying the user's visual focal attention during the moments of frustration. This can be applied in adaptive systems, gaming applications, intelligent tutoring systems and other applications that can leverage from the knowledge of the user's affective state to facilitate a better user experience."

# Tags: can be used for filtering projects.
# Example: `tags = ["machine-learning", "deep-learning"]`
tags = ["HCI", "Affective computing", "Empirical studies", "Arousal", "Physiological response", "Eye-tracking", "Pupillary response"]

# Optional external URL for project (replaces project detail page).
external_link = "https://www.researchgate.net/project/Sensing-arousal-during-visual-interaction"

# Featured image
# To use, add an image named `featured.jpg/png` to your project's folder. 
[image]
  # Caption (optional)
  caption = "Image showing the relationship betweeen arousal and performance (Yerkes & Dodson, 1908)"

  # Focal point (optional)
  # Options: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight
  focal_point = "Smart"
+++
